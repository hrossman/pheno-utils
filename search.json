[
  {
    "objectID": "data_loader.html",
    "href": "data_loader.html",
    "title": "Data loader",
    "section": "",
    "text": "source\n\nDataLoader\n\n DataLoader (dataset:str, base_path:str='/home/ec2-user/studies/hpp/',\n             cohort:str='10k', age_sex_dataset:str='population',\n             skip_dfs:List[str]=[], unique_index:bool=False,\n             valid_dates:bool=False, valid_stage:bool=False,\n             flexible_field_search:bool=False, errors:str='raise')\n\nClass to load multiple tables from a dataset and allows to easily access their fields.\nArgs:\ndataset (str): The name of the dataset to load.\nbase_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\ncohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\nage_sex_dataset (str, optional): The name of the dataset to use for computing age and sex. Defaults to POPULATION_DATASET.\nskip_dfs (list, optional): A list of tables (or substrings that match to tables) to skip when loading the data. Defaults to [].\nunique_index (bool, optional): Whether to ensure the index of the data is unique. Defaults to False.\nvalid_dates (bool, optional): Whether to ensure that all timestamps in the data are valid dates. Defaults to False.\nvalid_stage (bool, optional): Whether to ensure that all research stages in the data are valid. Defaults to False.\nflexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\nerrors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n    Possible values are 'raise', 'warn' and 'ignore'. Defaults to 'raise'.\nAttributes:\ndict (pd.DataFrame): The data dictionary for the dataset, containing information about each field.\ndfs (dict): A dictionary of dataframes, one for each table in the dataset.\nfields (list): A list of all fields in the dataset.\ndataset (str): The name of the dataset being used.\ncohort (str): The name of the cohort being used.\nbase_path (str): The base path where the data is stored.\ndataset_path (str): The full path to the dataset being used.\nage_sex_dataset (str): The name of the dataset being used to compute age and sex.\nskip_dfs (list): A list of tables to skip when loading the data.\nunique_index (bool): Whether to ensure the index of the data is unique.\nvalid_dates (bool): Whether to ensure that all timestamps in the data are valid dates.\nvalid_stage (bool): Whether to ensure that all research stages in the data are valid.\nflexible_field_search (bool): Whether to allow regex field search.\nerrors (str): Whether to raise an error or issue a warning if missing data is encountered.\nUse the dataset name to load the dataset. It may contain multiple tables. Age / sex will be added to the data by default. The default base_path is set to work on the research platform.\n\ndl = DataLoader('fundus')\ndl\n\nDataLoader for fundus with\n78 fields\n2 tables: ['fundus', 'age_sex']\n\n\nThe DataLoader class contains several usefull attributes\nThe data dictionary of the dataset displays the description of each field.\n\ndl.dict.head(3)\n\n\n\n\n\n\n\n\nfield_string\ndescription_string\nparent_dataframe\nrelative_location\nvalue_type\nunits\nsampling_rate\nitem_type\narray\ncohorts\ndata_type\ndebut\npandas_dtype\n\n\ntabular_field_name\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nFundus image (left)\nFundus image (left)\nNaN\nfundus.parquet\nText\nNone\nNaN\nBulk\nSingle\n10K\nimage\n2021-02-17\nstring\n\n\nfundus_image_right\nFundus image (right)\nFundus image (right)\nNaN\nfundus.parquet\nText\nNone\nNaN\nBulk\nSingle\n10K\nimage\n2021-02-17\nstring\n\n\ncollection_date\nCollection date (YYYY-MM-DD)\nCollection date (YYYY-MM-DD)\nNaN\nfundus.parquet\nDate\nTime\nNaN\nData\nSingle\n10K\ntabular\n2021-02-17\ndatetime64[ns]\n\n\n\n\n\n\n\n\ndl.dfs['fundus'].head(3)\n\n\n\n\n\n\n\n\n\n\n\nfundus_image_left\nfundus_image_right\ncollection_date\nartery_average_width_left\nartery_average_width_right\nartery_distance_tortuosity_left\nartery_distance_tortuosity_right\nartery_fractal_dimension_left\nartery_fractal_dimension_right\nartery_squared_curvature_tortuosity_left\n...\nvein_fractal_dimension_left\nvein_fractal_dimension_right\nvein_squared_curvature_tortuosity_left\nvein_squared_curvature_tortuosity_right\nvein_tortuosity_density_left\nvein_tortuosity_density_right\nvein_vessel_density_left\nvein_vessel_density_right\nvessel_density_left\nvessel_density_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2022-11-16\n18430.284751\n19038.547771\n3.668175\n3.271147\n1.355673\n1.343602\n40.648267\n...\n1.410553\n1.403108\n14.208195\n6.098432\n0.700187\n0.698546\n0.046645\n0.045864\n0.080377\n0.078671\n\n\n1\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2022-06-30\n17315.398780\n19099.489575\n2.095461\n1.634782\n1.368933\n1.363413\n24.253169\n...\n1.387527\n1.332864\n8.999069\n8.702682\n0.740806\n0.708911\n0.037896\n0.046853\n0.074197\n0.064578\n\n\n2\n10k\n00_00_visit\n0\n/path/to/file\n/path/to/file\n2021-10-05\n15375.866993\n19855.576862\n2.776472\n2.747015\n1.360404\n1.362699\n9.742353\n...\n1.411881\n1.408791\n13.119227\n9.936669\n0.627281\n0.675100\n0.053022\n0.048063\n0.079515\n0.082102\n\n\n\n\n3 rows × 76 columns\n\n\n\nAll availbale fields (columns) in all tables can be listed.\n\ndl.fields[:5]\n\n['artery_average_width_left',\n 'artery_average_width_right',\n 'artery_distance_tortuosity_left',\n 'artery_distance_tortuosity_right',\n 'artery_fractal_dimension_left']\n\n\nAccess any of the fields (e.g., vein_average_width_right, age) or indices (e.g., research_stage) from any of the tables via the data loader API.\n\ndl[['research_stage', 'vein_average_width_right', 'age', 'sex']]\n\n\n\n\n\n\n\n\n\n\n\nvein_average_width_right\nresearch_stage\nage\nsex\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n18436.428634\n00_00_visit\n43.5\n0\n\n\n1\n10k\n00_00_visit\n0\n18888.160314\n00_00_visit\n53.7\n1\n\n\n2\n10k\n00_00_visit\n0\n19013.865043\n00_00_visit\n26.2\n0\n\n\n3\n10k\n00_00_visit\n0\n18809.012493\n00_00_visit\n44.6\n1\n\n\n4\n10k\n00_00_visit\n0\n19428.986690\n00_00_visit\n50.3\n0\n\n\n\n\n\n\n\nAccess time series or bulk data that is stored separately for each sample via the data loader API. In the following example, the data loader retrieves the relative path of each sample’s bulk file from the main table (where it is stored in the field fundus_image_left), converts it to an absolute path, and loads the file. This is repeated for 2 samples and returned as a list. In the case of parquet DataFrames, there is no need to define the load_func and multiple DFs are concatenated by deafult.\n\ndl.load_sample_data('fundus_image_left', [0, 1], load_func=show_fundus)\n\n[None, None]\n\n\n\n\n\n\n\n\nYou can perform flexible field search (with regex support), when initializing the DataLoader as follows:\n\ndl = DataLoader('fundus', flexible_field_search=True)\n\nFor example, the following command will search for any field starting with “fractal”.\n\ndl['^fractal']\n\n\n\n\n\n\n\n\n\n\n\nfractal_dimension_left\nfractal_dimension_right\n\n\nparticipant_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n10k\n00_00_visit\n0\n1.564989\n1.520885\n\n\n1\n10k\n00_00_visit\n0\n1.542311\n1.534158\n\n\n2\n10k\n00_00_visit\n0\n1.482051\n1.545097\n\n\n3\n10k\n00_00_visit\n0\n1.548773\n1.539352\n\n\n4\n10k\n00_00_visit\n0\n1.554922\n1.557029\n\n\n\n\n\n\n\nYou can summarize a field or set of fields by the following command\n\ndl.describe_field(['fundus_image_right', 'collection_date'])\n\n\n\n\n\n\n\n\nfundus_image_right\ncollection_date\n\n\n\n\nfield_string\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\ndescription_string\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\nparent_dataframe\nNaN\nNaN\n\n\nrelative_location\nfundus.parquet\nfundus.parquet\n\n\nvalue_type\nText\nDate\n\n\nunits\nNone\nTime\n\n\nsampling_rate\nNaN\nNaN\n\n\nitem_type\nBulk\nData\n\n\narray\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n\n\ndata_type\nimage\ntabular\n\n\ndebut\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\ndatetime64[ns]\n\n\ncount\n5\n5\n\n\nunique\n1\n5\n\n\nmost_frequent\n/path/to/file\n2021-10-05\n\n\nmin\nNaN\nNaN\n\n\nmax\nNaN\nNaN\n\n\nmean\nNaN\nNaN\n\n\nmedian\nNaN\nNaN\n\n\nstd\nNaN\nNaN"
  },
  {
    "objectID": "cgm_plots.html",
    "href": "cgm_plots.html",
    "title": "CGM plots",
    "section": "",
    "text": "source\n\nCGMPlot\n\n CGMPlot (cgm_df:pandas.core.frame.DataFrame,\n          diet_df:Optional[pandas.core.frame.DataFrame]=None,\n          cgm_date_col:str='collection_timestamp', gluc_col:str='glucose',\n          diet_date_col:str='collection_timestamp',\n          diet_text_col:str='shortname_eng',\n          ax:Optional[matplotlib.axes._axes.Axes]=None, smooth:bool=False,\n          sleep_tuples:Optional[List[Tuple[pandas._libs.tslibs.timestamps.\n          Timestamp,pandas._libs.tslibs.timestamps.Timestamp]]]=None)\n\nInitialize a CGMPlot object.\nArgs: cgm_df (pd.DataFrame): DataFrame containing the glucose measurements. diet_df (Optional[pd.DataFrame], optional): DataFrame containing the diet data. Defaults to None. cgm_date_col (str, optional): Name of the date column in cgm_df. Defaults to “Date”. gluc_col (str, optional): Name of the glucose column in cgm_df. Defaults to “glucose”. diet_date_col (str, optional): Name of the date column in diet_df. Defaults to “Date”. diet_text_col (str, optional): Name of the text column in diet_df. Defaults to “shortname_eng”. ax (Optional[plt.Axes], optional): Matplotlib Axes object to plot on. Defaults to None. smooth (bool, optional): Apply smoothing to the glucose curve. Defaults to False. sleep_tuples (Optional[List[Tuple[pd.Timestamp, pd.Timestamp]]], optional): List of sleep start and end times. Defaults to None.\n\ncgm_df= pd.read_parquet(\"./examples/cgm/cgm_sample_data.parquet\")\ncgm_df.head()\n\n\n\n\n\n\n\n\n\n\nglucose\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n111.6\n\n\n2020-05-25 11:03:00+03:00\n1000001\n79.2\n\n\n2020-05-25 11:18:00+03:00\n1000001\n84.6\n\n\n2020-05-25 11:33:00+03:00\n1000001\n106.2\n\n\n2020-05-25 11:48:00+03:00\n1000001\n102.6\n\n\n\n\n\n\n\n\ndiet_df = pd.read_parquet(\"./examples/diet_logging/diet_sample_data.parquet\")\ndiet_df.head()\n\n\n\n\n\n\n\n\n\ncollection_timestamp\nfood_id\nweight\nshortname_eng\n\n\nparticipant_id\ncohort\n\n\n\n\n\n\n\n\n0\n10k\n2020-05-25 08:15:00+03:00\n1007294\n40.0\nCoffee\n\n\n10k\n2020-05-25 08:15:00+03:00\n1007417\n87.0\nYellow Cheese\n\n\n10k\n2020-05-25 08:15:00+03:00\n1008624\n6.0\nAlmonds\n\n\n10k\n2020-05-25 08:15:00+03:00\n1011642\n12.0\nBrazil nuts\n\n\n10k\n2020-05-25 10:05:00+03:00\n1007118\n100.0\nHummus\n\n\n\n\n\n\n\n\nstart_date = pd.to_datetime('2020-05-25',utc=True)\nend_date = pd.to_datetime('2020-05-27',utc=True)\n\nsample_days = cgm_df[(cgm_df.index.get_level_values('collection_timestamp') &gt;= start_date) \\\n                     & (cgm_df.index.get_level_values('collection_timestamp') &lt;= end_date)]\n\n\ncgmplt = CGMPlot(cgm_df=sample_days.reset_index(),\n                 cgm_date_col=\"collection_timestamp\",\n                 gluc_col=\"glucose\",\n                 diet_df=diet_df.iloc[9:],\n                 diet_date_col=\"collection_timestamp\",\n                 smooth=True)\ncgmplt.plot()\n\n\n\n\n\n\nAGP\n\nsource\n\nAGP\n\n AGP (cgm_df:pandas.core.frame.DataFrame,\n      cgm_date_col:str='collection_timestamp', gluc_col:str='glucose',\n      ax:Optional[matplotlib.axes._axes.Axes]=None)\n\nInitialize an AGP object.\nArgs: cgm_df (pd.DataFrame): DataFrame containing the glucose measurements. cgm_date_col (str, optional): Name of the date column in cgm_df. Defaults to “collection_timestamp”. gluc_col (str, optional): Name of the glucose column in cgm_df. Defaults to “glucose”. ax (Optional[plt.Axes], optional): Matplotlib Axes object to plot on. Defaults to None.\n\nagp = AGP(cgm_df=cgm_df.reset_index(), cgm_date_col=\"collection_timestamp\", gluc_col=\"glucose\")\nagp.plot()"
  },
  {
    "objectID": "basic_plots.html",
    "href": "basic_plots.html",
    "title": "Basic plots",
    "section": "",
    "text": "source\n\nhist_ecdf_plots\n\n hist_ecdf_plots (data:pandas.core.frame.DataFrame, col:str,\n                  feature_str:Optional[str]=None, gender_col:str='sex')\n\nPlots histograms and empirical cumulative distribution functions (ECDFs) from a DataFrame for a specific column.\nArgs: data: The input DataFrame containing the data to plot. col: The column name to plot. feature_str: The title of the plot. If not provided, the column name will be used. gender_col: The column name indicating sex (default is ‘sex’ - female:0; male:1).\nReturns: None\n\ndata = generate_synthetic_data(n=1000)\nhist_ecdf_plots(data=data, col=\"val1\")\n\n\n\n\n\nsource\n\n\nshow_fundus\n\n show_fundus (fname:str)\n\nDisplay a fundus image from an input file path. Args: fname (str): The file path to the fundus image."
  },
  {
    "objectID": "meta_loader.html",
    "href": "meta_loader.html",
    "title": "Metadata loader",
    "section": "",
    "text": "source\n\nMetaLoader\n\n MetaLoader (base_path:str='/home/ec2-user/studies/hpp/',\n             cohort:str='10k', flexible_field_search:bool=False,\n             errors:str='raise', **kwargs)\n\nClass to load multiple dictionaries and allows to easily access the relevant fields.\nArgs:\nbase_path (str, optional): The base path where the data is stored. Defaults to DATASETS_PATH.\ncohort (str, optional): The name of the cohort within the dataset. Defaults to COHORT.\nflexible_field_search (bool, optional): Whether to allow regex field search. Defaults to False.\nerrors (str, optional): Whether to raise an error or issue a warning if missing data is encountered.\n    Possible values are 'raise', 'warn' and 'ignore'. Defaults to 'raise'.\n**kwargs: Additional keyword arguments to pass to a DataLoader class.\nAttributes:\ndicts (pd.DataFrame): A dictionary of data dictionaries (dataframes) of all availbale datasets in the base_path.\nfields (list): A list of all fields.\ncohort (str): The name of the cohort being used.\nbase_path (str): The base path where the data is stored.\nflexible_field_search (bool): Whether to allow regex field search.\nerrors (str): Whether to raise an error or issue a warning if missing data is encountered.\nkwargs (dict): Additional keyword arguments to pass to a DataLoader class.\nThe MetaLoader can be used to query all availbale fields throughout all datasets. In the following example, 3 datasets are available.\n\nml = MetaLoader()\nml\n\nMetaLoader for: examples/*\nwith 79 fields\n3 datasets:\n['cgm'\n 'diet_logging'\n 'fundus']\n\n\nThe object contains only the data dictionaries (metadata) of these datasets, where the columns correspond to columns in the data tables of the dataset (e.g., fundus).\n\nml.dicts['fundus']\n\n\n\n\n\n\n\ntabular_field_name\nfundus_image_left\nfundus_image_right\ncollection_date\n\n\n\n\ndataset\nfundus\nfundus\nfundus\n\n\nfield_string\nFundus image (left)\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\ndescription_string\nFundus image (left)\nFundus image (right)\nCollection date (YYYY-MM-DD)\n\n\nparent_dataframe\nNaN\nNaN\nNaN\n\n\nrelative_location\nfundus.parquet\nfundus.parquet\nfundus.parquet\n\n\nvalue_type\nText\nText\nDate\n\n\nunits\nNone\nNone\nTime\n\n\nsampling_rate\nNaN\nNaN\nNaN\n\n\nitem_type\nBulk\nBulk\nData\n\n\narray\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n\n\ndata_type\nimage\nimage\ntabular\n\n\ndebut\n2021-02-17\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\nstring\ndatetime64[ns]\n\n\n\n\n\n\n\nYou can query fields from multiple datasets directly:\n\nml[['glucose', 'fundus_image_left']]\n\n\n\n\n\n\n\ntabular_field_name\ncgm/glucose\nfundus/fundus_image_left\n\n\n\n\ndataset\ncgm\nfundus\n\n\nfield_string\nGlucose\nFundus image (left)\n\n\ndescription_string\ncgm temporal glucose values\nFundus image (left)\n\n\nparent_dataframe\nNaN\nNaN\n\n\nrelative_location\ncgm_sample_data.parquet\nfundus.parquet\n\n\nvalue_type\nSeries data, continous\nText\n\n\nunits\nmg/dl\nNone\n\n\nsampling_rate\n15min\nNaN\n\n\nitem_type\nData\nBulk\n\n\narray\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n\n\ndata_type\ntime series\nimage\n\n\ndebut\n2018-12-27\n2021-02-17\n\n\npandas_dtype\nfloat\nstring\n\n\n\n\n\n\n\nYou can then use the MetaLoader to load the actual data of fields from multiple datasets. Here we load glucose from the CGM dataset, and fundus_image_left from the fundus dataset.\n\nml.load(['glucose' ,'fundus_image_left']).head()\n\n\n\n\n\n\n\n\n\n\n\n\n\nglucose\nfundus_image_left\n\n\nparticipant_id\ncollection_timestamp\nconnection_id\ncohort\nresearch_stage\narray_index\n\n\n\n\n\n\n0\n2020-05-25 10:48:00+03:00\n1000001\n10k\n00_00_visit\n0\n111.6\n/path/to/file\n\n\n2020-05-25 11:03:00+03:00\n1000001\n10k\n00_00_visit\n0\n79.2\n/path/to/file\n\n\n2020-05-25 11:18:00+03:00\n1000001\n10k\n00_00_visit\n0\n84.6\n/path/to/file\n\n\n2020-05-25 11:33:00+03:00\n1000001\n10k\n00_00_visit\n0\n106.2\n/path/to/file\n\n\n2020-05-25 11:48:00+03:00\n1000001\n10k\n00_00_visit\n0\n102.6\n/path/to/file\n\n\n\n\n\n\n\nYou may use more flexible search queries using regex and various properties of the fields. Both the get() method and load() method support the same syntax.\n\nExample: get all bulk data fields.\n\n\nml.get('bulk', flexible=True, prop='item_type')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/cgm_filename\nfundus/fundus_image_left\nfundus/fundus_image_right\n\n\n\n\ndataset\ncgm\nfundus\nfundus\n\n\nfield_string\nCGM timeseries\nFundus image (left)\nFundus image (right)\n\n\ndescription_string\nName of the file containing the participants' ...\nFundus image (left)\nFundus image (right)\n\n\nparent_dataframe\nNaN\nNaN\nNaN\n\n\nrelative_location\ncgm_sample_data.parquet\nfundus.parquet\nfundus.parquet\n\n\nvalue_type\nText\nText\nText\n\n\nunits\nNaN\nNone\nNone\n\n\nsampling_rate\nNaN\nNaN\nNaN\n\n\nitem_type\nBulk\nBulk\nBulk\n\n\narray\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n\n\ndata_type\ntext\nimage\nimage\n\n\ndebut\n2018-12-27\n2021-02-17\n2021-02-17\n\n\npandas_dtype\nstring\nstring\nstring\n\n\n\n\n\n\n\n\nExample: get all fields that include “mg” in their units\n\n\nml.get('mg', flexible=True, prop='units')\n\n\n\n\n\n\n\ntabular_field_name\ncgm/1st qu_\ncgm/3rd qu_\ncgm/auc\ncgm/ea1c\ncgm/glucose\ncgm/gmi\ncgm/iqr\ncgm/mad\ncgm/mag\ncgm/mage\n...\ncgm/modd\ncgm/range\ncgm/sd\ncgm/sdb\ncgm/sdbdm\ncgm/sddm\ncgm/sdhhmm\ncgm/sdw\ncgm/sdwsh\ndiet_logging/sodium_mg\n\n\n\n\ndataset\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\n...\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ncgm\ndiet_logging\n\n\nfield_string\n1st quantile\n3rd quantile\nAUC\neA1C\nGlucose\nGMI\nIQR\nMAD\nMAG\nMAGE\n...\nMODD\nRange\nSD\nSDb\nSDbdm\nSDdm\nSDhhmm\nSDw\nSDwsh\nSodium intake per food logged\n\n\ndescription_string\nFirst quantile of all glucose values.\nThird quantile of all glucose values.\nHourly average AUC. This measure integrates, t...\nA linear transformation of the mean glucose va...\ncgm temporal glucose values\nA linear transformation of the mean glucose va...\nInterquartile range (IQR), calculated as the d...\nMedian Absolute Deviation (MAD). This is a mea...\nMean Absolute Glucose (MAG). This is a measure...\nMean Amplitude of Glycemic Excursions (MAGE), ...\n...\nMean difference between glucose values obtaine...\nDifference between the maximum and minimum glu...\nStandard deviation of all glucose values.\nSD between days, within time points. Mean valu...\nSD between days, within time points, corrected...\nHorizontal SD. SD of the mean glucose values, ...\nSD between time points. Standard deviation of ...\nVertical SD within days. Average value of the ...\nSD within series. Taking hour-long intervals t...\nSodium intake per food logged\n\n\nparent_dataframe\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nrelative_location\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\n...\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ncgm_sample_data.parquet\ndiet_sample_data.parquet\n\n\nvalue_type\nContinuous\nContinuous\nContinuous\nContinuous\nSeries data, continous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\n...\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\nContinuous\n\n\nunits\nmg/dl\nmg/dl\nmg/dl*h\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\n...\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg/dl\nmg\n\n\nsampling_rate\nNaN\nNaN\nNaN\nNaN\n15min\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\nitem_type\nData\nData\nData\nData\nData\nData\nData\nData\nData\nData\n...\nData\nData\nData\nData\nData\nData\nData\nData\nData\nData\n\n\narray\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\n...\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\nSingle\n\n\ncohorts\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n...\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n10K\n\n\ndata_type\ntabular\ntabular\ntabular\ntabular\ntime series\ntabular\ntabular\ntabular\ntabular\ntabular\n...\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\ntabular\nTime Series\n\n\ndebut\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n...\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2018-12-27\n2019-09-01\n\n\npandas_dtype\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\n...\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\nfloat\n\n\n\n\n14 rows × 24 columns"
  },
  {
    "objectID": "basic_analysis.html",
    "href": "basic_analysis.html",
    "title": "Basic analysis",
    "section": "",
    "text": "try:\n    from smart_open import open\nexcept:\n    print(\"smart_open not installed, please pip install smart-open\")\n\n\nsource\n\ncustom_describe\n\n custom_describe (df:pandas.core.frame.DataFrame)\n\nGenerates a custom summary statistics dataframe for mixed data types.\nArgs: df: The input pandas DataFrame\nReturns: A pandas DataFrame containing the summary statistics\n\ndata = generate_synthetic_data(n=100)\n\ncustom_describe(data[[\"date_of_research_stage\", \"sex\", \"val2\"]])\n\n\n\n\n\n\n\n\ndate_of_research_stage\nsex\nval2\n\n\n\n\ncount\n100\n100.0\n100.0\n\n\nunique\n97\n2.0\n100.0\n\n\nmost_frequent\nNaN\n0.0\n0.489319\n\n\nmin\n2020-01-02 00:00:00\n0.0\n0.489319\n\n\nmax\n2023-04-09 00:00:00\n1.0\n42.71348\n\n\nmean\nNaN\n0.41\n25.464088\n\n\nmedian\nNaN\n0.0\n25.314398\n\n\nstd\nNaN\n0.494311\n9.464398\n\n\n\n\n\n\n\n\nsource\n\n\nassign_nearest_research_stage\n\n assign_nearest_research_stage (dataset:pandas.core.frame.DataFrame,\n                                population:pandas.core.frame.DataFrame,\n                                max_days:int=60,\n                                stages:List[str]=['visit'],\n                                agg:Optional[str]='first')\n\nAssign the nearest research stage to each record in a dataset.\nArgs: dataset (pd.DataFrame): The dataset containing records to be assigned research stages. population (pd.DataFrame): The population data with participant_id, cohort, research_stage, and research_stage_date. max_days (int, optional): The maximum number of days allowed between the collection date and research stage date. Defaults to 60. stages (List[str], optional): The list of types of research stages to consider. Defaults to [‘visit’]. agg (Union[str, None], optional): The aggregation function to be used when (optionally) aggregating multiple rows from the same research stage. The rows are already sorted by distance from the date of the research stage. Can be ‘first’ (closest), ‘last’ (farthest), ‘mean’, ‘min’, ‘max’, or None. Defaults to ‘first’.\nReturns: pd.DataFrame: The dataset with the nearest research stage assigned to each record."
  },
  {
    "objectID": "ecg_analysis.html",
    "href": "ecg_analysis.html",
    "title": "ECG analysis",
    "section": "",
    "text": "source\n\nvis_ecg\n\n vis_ecg (values_df:pandas.core.frame.DataFrame)\n\nVisualize ECG data for 12 leads.\nArgs: values_df (pd.DataFrame): A DataFrame containing ECG data with 12 columns, one for each lead.\nReturns: None: Displays a 3x4 grid of ECG plots for the 12 leads.\n\nsource\n\n\nget_hrv_df\n\n get_hrv_df (ECG_df:pandas.core.frame.DataFrame, sr:int=1000)\n\nCompute the Heart Rate Variability (HRV) metrics for each ECG lead in the input DataFrame.\nArgs: ECG_df (pd.DataFrame): A DataFrame containing ECG data with one column for each lead. sr (int, optional): The sampling rate of the ECG data. Defaults to 1000.\nReturns: pd.DataFrame: A DataFrame containing HRV metrics for each ECG lead."
  },
  {
    "objectID": "subset_loader.html",
    "href": "subset_loader.html",
    "title": "Subset loader",
    "section": "",
    "text": "source\n\nload_subset\n\n load_subset (subset:str, dataset:str=None, loader:str='data',\n              age_sex_dataset=None, **kwargs)\n\nWrapper for loading a train/test subset of a dataset.\nArgs:\nsubset (str): Can be one of 'train', 'test_01', 'test_02', 'test_final'.\ndataset (str): Name of the dataset to load. Not needed when requesting a MetaLoader.\nloader (str): Can be one of 'meta', 'data'.\n**kwargs: Additional keyword arguments to be passed to PhenoLoader / MetaLoader.\nReturns:\nDataLoader MetaLoader object: An object for the specified subset of the dataset."
  },
  {
    "objectID": "blandaltman_plots.html",
    "href": "blandaltman_plots.html",
    "title": "Bland-Altman plots",
    "section": "",
    "text": "source\n\nbland_altman_triple_plot\n\n bland_altman_triple_plot (data:pandas.core.frame.DataFrame, m1_col:str,\n                           m2_col:str, feature_str:str='')\n\nGenerates a triple plot consisting of a scatter correlation plot, Bland-Altman plot, and a percentage Bland-Altman plot.\nArgs: data (pd.DataFrame): A pandas DataFrame containing the data. m1_col (str): The name of the first measurement column in the DataFrame. m2_col (str): The name of the second measurement column in the DataFrame. feature_str (str, optional): A string to include in the title of the plots. Defaults to ““.\nReturns: None\n\ndata = generate_synthetic_data(n=1000)\n\nbland_altman_triple_plot(data=data, m1_col=\"val1\",m2_col=\"val2\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "pheno-utils",
    "section": "",
    "text": "Viz functions, loaders, mergers.\nWORK IN PROGRESS"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "pheno-utils",
    "section": "Install",
    "text": "Install\npip install pheno_utils"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "pheno-utils",
    "section": "How to use",
    "text": "How to use\nExamples:\n\ndata = generate_synthetic_data(n=1000)\nhist_ecdf_plots(data=data, col=\"val1\")\n\n\n\n\n\nage_refplots = GenderAgeRefPlot(data, \"val1\")\nage_refplots.plot()"
  },
  {
    "objectID": "date_plots.html",
    "href": "date_plots.html",
    "title": "Dates plots",
    "section": "",
    "text": "source\n\ndates_dist_plot\n\n dates_dist_plot (df:pandas.core.frame.DataFrame, col:str,\n                  sampling_period:str='W-MON', ax:Union[ForwardRef('Extens\n                  ionArray'),numpy.ndarray,ForwardRef('Index'),ForwardRef(\n                  'Series'),List,range,NoneType]=None,\n                  date_col:str='collection_date',\n                  ylim:Optional[Tuple[float,float]]=None,\n                  quantiles:Optional[List[Tuple[float,str]]]=None)\n\nCreates a scatter plot of data points and their statistics based on a specified sampling period.\nArgs: df (pd.DataFrame): The input DataFrame containing the data. col (str): The column name in the DataFrame to plot. sampling_period (str, optional): The frequency to resample the data. Defaults to ‘W-MON’. ax (Optional[Axes], optional): A matplotlib axes object to plot on. Defaults to None. date_col (str, optional): The name of the date column in the DataFrame. Defaults to ‘collection_date’. ylim (Optional[Tuple[float, float]], optional): A tuple defining the y-axis limits. Defaults to None. quantiles (Optional[List[Tuple[float, str]]], optional): A list of tuples containing quantiles and their labels. Defaults to [(0.1, “10%”), (0.9, “90%”)].\n\ndata = generate_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2022-12-01\n57.777073\n1\n150.216212\n56.936487\n\n\n1\n2020-07-29\n53.770724\n1\n117.603875\n47.152785\n\n\n2\n2020-09-30\n51.326393\n1\n97.928950\n41.250308\n\n\n3\n2022-05-06\n61.217276\n0\n105.169939\n41.422605\n\n\n4\n2021-06-29\n45.835170\n0\n54.735540\n26.292285\n\n\n\n\n\n\n\n\ndates_dist_plot(data, col=\"val1\", date_col=\"date_of_research_stage\")"
  },
  {
    "objectID": "config.html",
    "href": "config.html",
    "title": "Config",
    "section": "",
    "text": "source\n\ngenerate_synthetic_data\n\n generate_synthetic_data (n:int=1000)\n\nGenerates a sample DataFrame containing age, gender, and value data.\nArgs: n: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with columns ‘age’, ‘gender’, and ‘val’.\n\nsource\n\n\ngenerate_synthetic_data_like\n\n generate_synthetic_data_like (df:pandas.core.frame.DataFrame, n:int=1000,\n                               random_seed:int=42)\n\nGenerate a sample DataFrame containing the same columns as df, but with random data.\nArgs:\ndf: The DataFrame whose columns should be used.\nn: The number of rows in the generated DataFrame.\nReturns: A pandas DataFrame with the same columns as df.\n\ndata = generate_synthetic_data()\ndata.head()\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2020-04-11\n71.216530\n1\n122.487606\n27.996005\n\n\n1\n2023-01-06\n66.211243\n1\n141.050268\n33.564803\n\n\n2\n2022-03-13\n38.190023\n1\n86.009637\n17.052614\n\n\n3\n2023-04-07\n65.760406\n1\n135.596689\n31.928730\n\n\n4\n2022-05-08\n66.785952\n1\n140.012493\n33.253471\n\n\n\n\n\n\n\n\ngenerate_synthetic_data_like(data.head(), n=5)\n\n\n\n\n\n\n\n\ndate_of_research_stage\nage_at_research_stage\nsex\nval1\nval2\n\n\nparticipant_id\n\n\n\n\n\n\n\n\n\n0\n2022-03-13\n65.760406\n1\n135.596689\n27.996005\n\n\n1\n2023-04-07\n66.211243\n1\n122.487606\n33.253471\n\n\n2\n2022-05-08\n38.190023\n1\n140.012493\n33.564803\n\n\n3\n2023-01-06\n71.216530\n1\n86.009637\n17.052614\n\n\n4\n2020-04-11\n66.785952\n1\n141.050268\n31.928730"
  },
  {
    "objectID": "sleep_plots.html",
    "href": "sleep_plots.html",
    "title": "Sleep plots",
    "section": "",
    "text": "source\n\nget_legend_colors\n\n get_legend_colors (cmap='muted')\n\n\nsource\n\n\nformat_xticks\n\n format_xticks (ax, format='%m/%d %H:%M')\n\nformat datestrings on x axis\n\nsource\n\n\nplot_channels\n\n plot_channels (channels:pandas.core.frame.DataFrame,\n                array_index:Optional[int]=None,\n                y_filter:Optional[Iterable[str]]=None,\n                ax:matplotlib.axes._axes.Axes=None,\n                discrete_events:Optional[Iterable[str]]=['sleep_stage',\n                'body_position'], time_col='collection_timestamp',\n                height=1.5, resample='1s', cmap='muted',\n                rename_channels={'actigraph': 'Actigraph',\n                'body_position': 'Body Position', 'heart_rate': 'Heart\n                Rate', 'heart_rate_raw': 'Heart Rate Raw', 'pat_infra':\n                'PAT Infra', 'pat_amplitude': 'PAT Amplitude', 'pat_lpf':\n                'PAT LPF', 'respiratory_movement': 'Respiratory Mov.',\n                'spo2': 'SpO2', 'snore_db': 'Snore dB', 'pat_view': 'PAT\n                View', 'sleep_stage': 'Sleep Stage'}, **kwargs)\n\nplot channels data for a given participant and array_index\n\nsource\n\n\nplot_events\n\n plot_events (events:pandas.core.frame.DataFrame,\n              array_index:Optional[int]=None,\n              x_start:str='collection_timestamp', x_end:str='event_end',\n              y:str='event', color:str='channel', cmap:str='muted',\n              set_xlim:bool=True, xlim:Iterable[float]=None,\n              figsize:Iterable[float]=[10, 4],\n              y_include:Optional[Iterable[str]]=None,\n              y_exclude:Optional[Iterable[str]]=None,\n              ax:matplotlib.axes._axes.Axes=None,\n              add_events:Optional[pandas.core.frame.DataFrame]=None,\n              rename_channels:dict={'PAT Amplitude': 'PAT', 'PulseRate':\n              'Heart Rate'}, rename_events:dict={})\n\nplot an events timeline for a given participant and array_index\n\nsource\n\n\nplot_sleep\n\n plot_sleep (events:pandas.core.frame.DataFrame,\n             channels:pandas.core.frame.DataFrame,\n             array_index:Optional[int]=None,\n             trim_to_events:Optional[bool]=True,\n             add_events:Optional[pandas.core.frame.DataFrame]=None,\n             event_filter:Optional[Iterable[str]]=None,\n             channel_filter:Optional[Iterable[str]]=['actigraph',\n             'pat_infra', 'body_position', 'snore_db', 'heart_rate',\n             'spo2'], event_height:float=2, channel_height:float=0.45,\n             width:float=10, aspect:float=0.2, style:str='whitegrid',\n             xlim:Iterable[float]=None, **kwargs)\n\nPlot sleep events and channels data.\nArgs:\nevents (pd.DataFrame): A pandas dataframe containing sleep events data.\nchannels (pd.DataFrame): A pandas dataframe containing raw channels data.\narray_index (int, optional): The index of the array. Defaults to None.\ntrim_to_events (bool, optional): Whether to trim the plot to the start and end of the events. Defaults to True.\nadd_events (pd.DataFrame, optional): Additional events data to include in the plot. Defaults to None.\nevent_filter (Iterable[str], optional): A list of events to include in the plot. Defaults to None.\nchannel_filter (Iterable[str], optional): A list of channels to include in the plot. Defaults to DEFAULT_CHANNELS.\nevent_height (float, optional): The height of the event plot in inches. Defaults to 2.\nchannel_height (float, optional): The height of each channel plot in inches. Defaults to 0.45.\nwidth (float, optional): The width of the plot in inches. Defaults to 10.\naspect (float, optional): The aspect ratio of the plot. Defaults to 0.2.\nstyle (str, optional): The seaborn style to use. Defaults to 'whitegrid'.\nxlim (List[float], optional): The x-axis limits of the plot. Defaults to None.\n**kwargs: Additional arguments to be passed to plot_channels().\nReturns:\nNone"
  },
  {
    "objectID": "age_reference_plots.html",
    "href": "age_reference_plots.html",
    "title": "Age reference plots",
    "section": "",
    "text": "source\n\nAgeRefPlot\n\n AgeRefPlot (data:pandas.core.frame.DataFrame, val_col:str,\n             age_col:str='age_at_research_stage', sex_col:str='sex',\n             sex:Optional[int]=None, val_color:Optional[str]=None,\n             ax_main:Optional[matplotlib.axes._axes.Axes]=None,\n             ax_agehist:Optional[matplotlib.axes._axes.Axes]=None,\n             ax_valhist:Optional[matplotlib.axes._axes.Axes]=None,\n             age_bins:Optional[numpy.ndarray]=None,\n             val_bins:Optional[numpy.ndarray]=None, linear_fit:bool=True,\n             lowess:bool=False, top_disp_perc:float=99,\n             bottom_disp_perc:float=1, percentiles_type:str='summary',\n             robust:bool=True, scale:float=1.0,\n             transform:Optional[Callable]=None, make_fig:bool=True)\n\nInitializes the AgeRefPlot class.\nArgs: data (pd.DataFrame): A pandas DataFrame containing the data. val_col (str): The name of the value column in the DataFrame. age_col (str): The name of the age column in the DataFrame. sex_col (str): The name of the sex column in the DataFrame. sex (Optional[int], optional): The sex to filter the data by. 0 for females and 1 for males. Defaults to None. val_color (Optional[str], optional): The color to use for the value plot. Defaults to None. ax_main (Optional[plt.Axes], optional): The main axis for the plot. Defaults to None. ax_agehist (Optional[plt.Axes], optional): The axis for the age histogram. Defaults to None. ax_valhist (Optional[plt.Axes], optional): The axis for the value histogram. Defaults to None. age_bins (Optional[np.ndarray], optional): The age bins for the histograms. Defaults to None. val_bins (Optional[np.ndarray], optional): The value bins for the histograms. Defaults to None. linear_fit (bool, optional): Whether to perform a linear fit on the data. Defaults to True. lowess (bool, optional): Whether to perform lowess smoothing on the data. Defaults to False. top_disp_perc (float, optional): The top percentile to use for display. Defaults to 99. bottom_disp_perc (float, optional): The bottom percentile to use for display. Defaults to 1. percentiles_type (str, optional): The type of percentiles to use. Must be one of [‘summary’, ‘1-percent intervals’, ‘5-percent intervals’, ‘10-percent intervals’]. Defaults to ‘summary’. robust (bool, optional): Whether to use a robust regression method (HuberRegressor) instead of ordinary least squares for linear_fit. Defaults to True. scale (float, optional): The scaling factor for the value column. Defaults to 1. transform (Optional[Callable], optional): The transformation function to apply to the value column. Defaults make_fig (bool, optional): Whether to create a new figure if axes are not provided. Defaults to True.\n\ndata = generate_synthetic_data(n=1000)\n\n\nrefplot = AgeRefPlot(data, \"val1\")\nrefplot.plot()\n\n\n\n\n\nsource\n\n\nGenderAgeRefPlot\n\n GenderAgeRefPlot (data:pandas.core.frame.DataFrame, val_col:str,\n                   age_col:str='age_at_research_stage', sex_col:str='sex',\n                   age_bins:Optional[numpy.ndarray]=None,\n                   val_bins:Optional[numpy.ndarray]=None,\n                   linear_fit:bool=True, lowess:bool=False,\n                   top_disp_perc:float=99, bottom_disp_perc:float=1,\n                   percentiles_type:str='summary', robust:bool=True,\n                   scale:float=1.0, transform:Optional[Callable]=None)\n\nInitializes the GenderAgeRefPlot class.\nArgs: data (pd.DataFrame): The input data containing age, value, and gender columns. val_col (str): The name of the value column in the data. age_col (str): The name of the age column in the DataFrame. sex_col (str): The name of the sex column in the DataFrame. age_bins (np.ndarray, optional): An array of age bin edges. val_bins (np.ndarray, optional): An array of value bin edges. linear_fit (bool, optional): Whether to fit a linear regression line. Defaults to True. lowess (bool, optional): Whether to fit a LOWESS curve. Defaults to False. top_disp_perc (float, optional): The top percentile for data display. Defaults to 99. bottom_disp_perc (float, optional): The bottom percentile for data display. Defaults to 1. percentiles_type (str, optional): The type of percentile calculation. Defaults to ‘summary’. robust (bool, optional): Whether to use a robust linear regression. Defaults to True. scale (float, optional): The scaling factor for the data. Defaults to 1. transform (Callable, optional): An optional function to apply to the data. Defaults to None.\n\ngender_refplots = GenderAgeRefPlot(data, \"val1\")\ngender_refplots.plot()"
  }
]